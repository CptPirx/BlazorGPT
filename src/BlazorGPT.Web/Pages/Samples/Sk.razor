@page "/sk"
@inherits SamplePage
@using BlazorGPT.Pipeline
@using Microsoft.SemanticKernel
@using Microsoft.SemanticKernel.TemplateEngine
@using System.Globalization
@using Microsoft.SemanticKernel.Skills.Core
@inject IOptions<PipelineOptions> PipelineOptions
@layout EmptyLayout
<h3>Semantic Kernel</h3>

 

<ConversationDisplay Conversation="@Conversation" Style="height: auto"/>

@code {

    [Inject]
    public ChatWrapper Chat { get; set; }

    [Inject]
    public KernelService KernelService { get; set; }

    

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {

            Conversation = new Conversation();
            // Create a new kernel. This is the main entry point to the Semantic Kernel.
            kernel = await KernelService.CreateKernelAsync();


            // This is the system prompt, ie the information that the system wants to share with the user.
            var systemPromptTemplate = 
@"You are an AI assistant that helps people find information.
The chat started at: {{ $startTime }}
The current time is: {{ time.now }}
Text selected:
{{ $selectedText }}";

            // This is the user prompt, ie the information that the user wants to share with the system.
            var selectedText = "The central Sahara is hyperarid, with sparse vegetation. The northern and southern reaches of the desert, along with the highlands, have areas of sparse grassland and desert shrub, with trees and taller shrubs in wadis, where moisture collects. In the central, hyperarid region, there are many subdivisions of the great desert: Tanezrouft, the Ténéré, the Libyan Desert, the Eastern Desert, the Nubian Desert and others. These extremely arid areas often receive no rain for years.";
            var userPromptTemplate = "{{ time.now }}: {{ $userMessage }}";


            kernel.ImportSkill(new TimeSkill(), "time");
            kernel.ImportSkill(new HttpSkill(), "http");
            kernel.ImportSkill(new TextMemorySkill(kernel.Memory), "memory");



            // We need a kernel context to store some information to pass to the prompts and the list
            // of available skills needed to render prompt templates.
            var context = kernel.CreateNewContext();

            // Put the selected document into the variable used by the system prompt (see 28-system-prompt.txt).
            context["selectedText"] = selectedText;

            // Demo another variable, e.g. when the chat started, used by the system prompt (see 28-system-prompt.txt).
            context["startTime"] = DateTimeOffset.Now.ToString("hh:mm:ss tt zz", CultureInfo.CurrentCulture);

            // This is the user message, store it in the variable used by 28-user-prompt.txt

            context["url"] = "https://www.bing.com";
            context["userMessage"] = "extract locations as a bullet point list.";

            // Instantiate the prompt renderer, which we will use to turn prompt templates
            // into strings, that we will store into a Chat history object, which is then sent
            // to the Chat Model.
            var promptRenderer = new PromptTemplateEngine();

            // Render the system prompt. This string is used to configure the chat.
            // This contains the context, ie a piece of a wikipedia page selected by the user.
            string systemMessage = await promptRenderer.RenderAsync(systemPromptTemplate, context);
      //      Console.WriteLine($"------------------------------------\n{systemMessage}");

            // Render the user prompt. This string is the query sent by the user
            // This contains the user request, ie "extract locations as a bullet point list"
            string userMessage = await promptRenderer.RenderAsync(userPromptTemplate, context);
       //     Console.WriteLine($"------------------------------------\n{userMessage}");

            // // // Client used to request answers to gpt-3.5-turbo
            // // var chatGPT = kernel.GetService<IChatCompletion>();

            
    
            // // // The full chat history. Depending on your scenario, you can pass the full chat if useful,
            // // // or create a new one every time, assuming that the "system message" contains all the
            // // // information needed.
            // // var chatHistory = chatGPT.CreateNewChat(systemMessage);

            // // // Add the user query to the chat history
            // // chatHistory.AddMessage(ChatHistory.AuthorRoles.User, userMessage);

            // // // Finally, get the response from AI
            // // string answer = await chatGPT.GenerateMessageAsync(chatHistory);
            // // Console.WriteLine($"------------------------------------\n{answer}");


            if (Conversation != null)
            {
                Conversation.AddMessage("system", systemMessage);
                Conversation.AddMessage("user", userMessage);

                StateHasChanged();

                // Conversation =
                await Chat.SendWithPipeline(kernel, Conversation, OnStreamCompletion);
                StateHasChanged();

            }
        }
    }

    public IKernel kernel { get; set; }
 
   

    [Inject]
    public NavigationManager? NavigationManager { get; set; }

 

}